"""ç‰¹å¾µé‡è¦æ€§åˆ†æè…³æœ¬

åˆ†ææ‰€æœ‰ç‰¹å¾µèˆ‡ traffic_volume çš„ç›¸é—œæ€§ï¼Œç”¨æ–¼æŒ‡å°ç‰¹å¾µé¸æ“‡ã€‚
"""
import pandas as pd
import numpy as np
import json
from pathlib import Path


def analyze_feature_importance(train_path: str = "blob/process/train_processed.csv",
                               output_path: str = "blob/analysis/feature_importance.json"):
    """åˆ†æç‰¹å¾µé‡è¦æ€§ä¸¦è¼¸å‡ºå ±å‘Š

    Args:
        train_path: è¨“ç·´è³‡æ–™è·¯å¾‘
        output_path: è¼¸å‡º JSON è·¯å¾‘
    """
    print("=" * 80)
    print("ğŸ“Š ç‰¹å¾µé‡è¦æ€§åˆ†æ")
    print("=" * 80)
    print()

    # è®€å–è¨“ç·´è³‡æ–™
    df = pd.read_csv(train_path)
    print(f"âœ“ è¼‰å…¥è³‡æ–™: {df.shape}")
    print()

    # åˆ†é›¢ç‰¹å¾µå’Œç›®æ¨™
    X = df.drop(columns=['ID', 'traffic_volume'])
    y = df['traffic_volume']

    # è¨ˆç®—æ¯å€‹ç‰¹å¾µèˆ‡ç›®æ¨™çš„ç›¸é—œæ€§
    correlations = []
    constant_features = []

    for col in X.columns:
        # æª¢æŸ¥æ˜¯å¦ç‚ºå¸¸æ•¸ç‰¹å¾µ
        if X[col].std() == 0:
            constant_features.append(col)
            continue

        corr = X[col].corr(y)

        # è·³é nan å€¼
        if pd.isna(corr):
            continue

        abs_corr = abs(corr)
        correlations.append({
            'feature': col,
            'correlation': float(corr),
            'abs_correlation': float(abs_corr)
        })

    if constant_features:
        print(f"âš ï¸ ç™¼ç¾ {len(constant_features)} å€‹å¸¸æ•¸ç‰¹å¾µï¼ˆå·²è·³éï¼‰:")
        for feat in constant_features[:5]:
            print(f"   - {feat}")
        if len(constant_features) > 5:
            print(f"   ... é‚„æœ‰ {len(constant_features) - 5} å€‹")
        print()

    # æŒ‰çµ•å°ç›¸é—œæ€§æ’åº
    correlations.sort(key=lambda x: x['abs_correlation'], reverse=True)

    # é¡¯ç¤ºå‰ 20 å€‹æœ€é‡è¦çš„ç‰¹å¾µ
    print("### å‰ 20 å€‹æœ€ç›¸é—œç‰¹å¾µï¼ˆæŒ‰çµ•å°ç›¸é—œæ€§ï¼‰")
    print()
    print(f"{'æ’å':<6} {'ç‰¹å¾µåç¨±':<35} {'ç›¸é—œæ€§':>12} {'çµ•å°å€¼':>12}")
    print("-" * 70)

    for i, item in enumerate(correlations[:20], 1):
        feature = item['feature']
        corr = item['correlation']
        abs_corr = item['abs_correlation']

        # æ¨™è¨˜ä¸åŒé¡å‹çš„ç‰¹å¾µ
        if feature.startswith('rush_'):
            marker = "ğŸ”¥"
        elif feature.startswith('temp_'):
            marker = "ğŸŒ¡ï¸"
        elif feature.startswith('weather_'):
            marker = "â˜ï¸"
        elif 'hour' in feature:
            marker = "â°"
        else:
            marker = "  "

        print(f"{i:<6} {marker} {feature:<33} {corr:>12.6f} {abs_corr:>12.6f}")

    print()
    print("-" * 70)
    print()

    # åˆ†é¡çµ±è¨ˆ
    print("### ç‰¹å¾µé¡åˆ¥çµ±è¨ˆ")
    print()

    categories = {
        'rush_': 'äº¤äº’ä½œç”¨ï¼ˆRush Hourï¼‰',
        'temp_': 'æº«åº¦ç›¸é—œ',
        'weather_': 'å¤©æ°£ç›¸é—œ',
        'hour': 'æ™‚é–“ç›¸é—œ',
        'base': 'åŸºæœ¬ç‰¹å¾µ'
    }

    for prefix, name in categories.items():
        if prefix == 'base':
            # åŸºæœ¬ç‰¹å¾µï¼šä¸å«ä»»ä½•å‰ç¶´
            features = [c for c in correlations
                       if not any(c['feature'].startswith(p) for p in ['rush_', 'temp_', 'weather_'])
                       and 'hour' not in c['feature']]
        else:
            features = [c for c in correlations if c['feature'].startswith(prefix) or prefix in c['feature']]

        if features:
            avg_corr = np.mean([f['abs_correlation'] for f in features])
            max_corr = max([f['abs_correlation'] for f in features])
            print(f"{name:30s}: {len(features):2d} å€‹ç‰¹å¾µ, å¹³å‡ç›¸é—œæ€§ {avg_corr:.4f}, æœ€å¤§ {max_corr:.4f}")

    print()
    print("-" * 70)
    print()

    # æ¨è–¦çš„ top-k ç‰¹å¾µ
    print("### æ¨è–¦çš„ç‰¹å¾µé¸æ“‡")
    print()

    for k in [5, 10, 15, 20]:
        top_features = [c['feature'] for c in correlations[:k]]
        avg_corr = np.mean([c['abs_correlation'] for c in correlations[:k]])
        print(f"Top-{k:2d}: å¹³å‡ç›¸é—œæ€§ {avg_corr:.4f}")
        if k == 15:
            print(f"        ç‰¹å¾µ: {', '.join(top_features[:5])}...")

    print()
    print("-" * 70)
    print()

    # æ™ºèƒ½ç‰¹å¾µé¸æ“‡å»ºè­°ï¼ˆè€ƒæ…®å¤šé …å¼å›æ­¸ï¼‰
    print("### ğŸ’¡ é‡å° Polynomial Regression çš„æ™ºèƒ½é¸æ“‡å»ºè­°")
    print()
    print("âš ï¸  æ³¨æ„ï¼šå–®è®Šé‡ç›¸é—œæ€§ä¸ç­‰æ–¼å¤šé …å¼å›æ­¸çš„ç‰¹å¾µé‡è¦æ€§ï¼")
    print()

    # éæ¿¾æ‰å¤šé‡å…±ç·šçš„æº«åº¦ç‰¹å¾µ
    smart_selection = []
    seen_temp_poly = False

    for c in correlations:
        feat = c['feature']

        # é¿å…åŒæ™‚é¸ temp, temp_squared, temp_cubedï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰
        if feat in ['temp_squared', 'temp_cubed']:
            if not seen_temp_poly:
                seen_temp_poly = True
            else:
                continue  # è·³éé‡è¤‡çš„æº«åº¦å¤šé …å¼

        # å¿…é ˆåŒ…å«çš„æ™‚é–“å¾ªç’°ç‰¹å¾µï¼ˆå³ä½¿ç›¸é—œæ€§ä½ï¼‰
        if feat in ['hour_sin', 'hour_cos']:
            # æå‡å„ªå…ˆç´š
            smart_selection.insert(0, c)
            continue

        # å¿…é ˆåŒ…å«çš„åŸºç¤ç‰¹å¾µ
        if feat in ['Rush Hour', 'temp', 'clouds_all', 'is_holiday']:
            smart_selection.insert(0, c)
            continue

        smart_selection.append(c)

    print("æ¨è–¦ Top-15ï¼ˆæ™ºèƒ½éæ¿¾ï¼Œé©åˆ Polynomial Regressionï¼‰:")
    smart_top15 = [c['feature'] for c in smart_selection[:15]]
    for i, feat in enumerate(smart_top15, 1):
        corr = next((c['correlation'] for c in correlations if c['feature'] == feat), 0.0)
        print(f"  {i:2d}. {feat:35s} ({corr:>7.4f})")

    print()
    print("-" * 70)
    print()

    # ä½ç›¸é—œæ€§ç‰¹å¾µï¼ˆå¯èƒ½æ˜¯é›œè¨Šï¼‰
    low_corr_features = [c for c in correlations if c['abs_correlation'] < 0.01]
    print(f"### ä½ç›¸é—œæ€§ç‰¹å¾µï¼ˆ|ç›¸é—œæ€§| < 0.01ï¼‰ï¼š{len(low_corr_features)} å€‹")
    if low_corr_features:
        print("é€™äº›ç‰¹å¾µå°é æ¸¬å¹«åŠ©ä¸å¤§ï¼Œå¯è€ƒæ…®ç§»é™¤ï¼š")
        for item in low_corr_features[:10]:
            print(f"  - {item['feature']}: {item['correlation']:.6f}")
        if len(low_corr_features) > 10:
            print(f"  ... é‚„æœ‰ {len(low_corr_features) - 10} å€‹")

    print()
    print("=" * 80)

    # å„²å­˜å®Œæ•´çµæœ
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    result = {
        'total_features': len(correlations),
        'analysis_date': pd.Timestamp.now().isoformat(),
        'correlations': correlations,
        'recommendations': {
            'top_5': [c['feature'] for c in correlations[:5]],
            'top_10': [c['feature'] for c in correlations[:10]],
            'top_15': [c['feature'] for c in correlations[:15]],
            'top_20': [c['feature'] for c in correlations[:20]],
            'smart_15': smart_top15,  # æ™ºèƒ½é¸æ“‡ï¼ˆè€ƒæ…®å¤šé …å¼å›æ­¸ï¼‰
        },
        'low_correlation': [c['feature'] for c in low_corr_features]
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    print(f"\nâœ“ å®Œæ•´åˆ†æçµæœå·²å„²å­˜: {output_path}")
    print()

    return correlations


if __name__ == "__main__":
    analyze_feature_importance()
